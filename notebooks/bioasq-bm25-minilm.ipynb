{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86e365a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install beir\n",
    "#!pip install -U pyarrow\n",
    "#!conda install -y pytorch torchvision -c pytorch-nightly\n",
    "#!conda install -y -c conda-forge sentence-transformers\n",
    "#!conda install -y datasets\n",
    "#!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a78c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7b4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(torch.backends.mps.is_available())\n",
    "#print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841966fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/beir/datasets/data_loader.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249a685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.expanduser(\"~/Google Drive/Shared drives/Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9522445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_docs(mesh_file=f\"{data_dir}/BioASQ/allMeSH_2020.json\"):\n",
    "    with open(mesh_file, \"r\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # first line does not contain data\n",
    "            if i == 0:\n",
    "                continue\n",
    "            obj = json.loads(line[:-2])\n",
    "            doc = {\n",
    "                'pmid': obj['pmid'],\n",
    "                'title': obj['title'],\n",
    "                'text': obj['abstractText'],\n",
    "                'mesh_terms': obj['meshMajor'],\n",
    "                'journal': obj['journal']\n",
    "            }\n",
    "            yield obj['pmid'], doc\n",
    "\n",
    "def iter_fixes(fixes_file=f\"{data_dir}/BioASQ/Manual-fixes - BioASQ-Task8b.csv\"):\n",
    "    #Add manual fixes provided by BEIR authors\n",
    "    with open(fixes_file, \"r\") as f:\n",
    "        csv_f = csv.reader(f)\n",
    "        for row in csv_f:\n",
    "            yield row[0], {\"pmid\": row[0], \"text\": row[2], \"title\": row[1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd696341",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"index\": {\n",
    "        \"number_of_shards\": 5,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"analysis\": {\n",
    "        \"analyzer\": {\n",
    "            \"custom_analyzer\": {\n",
    "                \"type\": \"custom\",\n",
    "                \"tokenizer\": \"standard\",\n",
    "                \"filter\": [\n",
    "                    \"lowercase\",\n",
    "                    \"custom_stemmer\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"filter\": {\n",
    "            \"custom_stemmer\": {\n",
    "                \"type\": \"stemmer\",\n",
    "                \"language\": 'minimal_english'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        \"pmid\": {\n",
    "            \"type\": \"keyword\"\n",
    "        },\n",
    "        \"title\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"text\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"journal\": {\n",
    "            \"type\": \"keyword\"\n",
    "        },\n",
    "        \"meshMajor\": {\n",
    "            \"type\": \"keyword\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d823af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticstore import Store\n",
    "from elasticsearch import AsyncElasticsearch\n",
    "es = AsyncElasticsearch(['http://localhost:9200'], timeout=300, retry_on_timeout=True, verify_certs=False)\n",
    "store = Store(es, 'bioasq', settings=settings, mappings=mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9987045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from aitertools import aiter\n",
    "\n",
    "async def aiter_docs(start):\n",
    "    for i in tqdm(islice(iter_docs(), start, None), total=14_9139_39-start):\n",
    "        yield i\n",
    "\n",
    "await store.bulk_update(aiter_docs(11370000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6a40cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "128it [00:00, 239.12it/s]\u001b[A\n",
      "776it [00:00, 1003.10it/s][A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(776, [])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def aiter_fixes():\n",
    "    for i in tqdm(iter_fixes()):\n",
    "        yield i\n",
    "\n",
    "await store.bulk_update(aiter_fixes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35f17060",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test dataset with 500 queries as used in BEIR\n",
    "test_data_path = f\"{data_dir}/BioASQ/Task8BGoldenEnriched\"\n",
    "with jsonlines.open(f'{data_dir}/BEIR/bioasq/queries.jsonl', 'w') as queries_out:\n",
    "    with open(f\"{data_dir}/BEIR/bioasq/qrels/test.tsv\", \"w\") as record_file:\n",
    "        # Write header\n",
    "        record_file.write(\"query-id\\tcorpus-id\\tscore\\n\")\n",
    "        for test_json in os.listdir(test_data_path):\n",
    "            with open(os.path.join(test_data_path, test_json), \"r\") as content:\n",
    "\n",
    "                queries_answers = json.load(content)\n",
    "\n",
    "                for query in queries_answers[\"questions\"]:\n",
    "                    query_line = {\"_id\": query[\"id\"], \"text\": query[\"body\"]}\n",
    "                    queries_out.write(query_line)\n",
    "\n",
    "                    for doc in query[\"documents\"]:\n",
    "                        doc_id = doc.split(\"/\")[-1]\n",
    "                        relevance = 1\n",
    "\n",
    "                        record_file.write(f\"{query['id']}\\t{doc_id}\\t{relevance}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "768bcbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty file because we have already indexed into ES\n",
    "with open(f'{data_dir}/BEIR/bioasq/corpus.jsonl', 'w') as f:\n",
    "    f.write('{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bd70f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ab5a7906c44b86ba43fd4517a9cce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TEST DATASET RESULTS ###\n",
    "\n",
    "import json\n",
    "\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "dataset = \"bioasq\"\n",
    "data_path = f'{data_dir}/BEIR/{dataset}'\n",
    "_, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04f18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use first 100\n",
    "query_keys = list(queries.keys())\n",
    "queries_ = {k: v for k, v in queries.items() if k in query_keys[:100]}\n",
    "qrels_ = {k: v for k, v in qrels.items() if k in query_keys[:100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def1747",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2355d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14914604"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vectorspace.store import Store as ESDict\n",
    "from elasticsearch import Elasticsearch\n",
    "corpus = ESDict(Elasticsearch(['http://localhost:9200']), 'bioasq')\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb278d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "que: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:04<00:00, 64.24s/it]\n"
     ]
    }
   ],
   "source": [
    "model = BM25(index_name=dataset, hostname='localhost', initialize=False, keys={\"title\": \"title\", \"body\": \"text\"})\n",
    "retriever = EvaluateRetrieval(model)\n",
    "#### Retrieve dense results (format of results is identical to qrels)\n",
    "bm25_results = retriever.retrieve(corpus, queries_)\n",
    "# Save scores for top 1000 docs for each query, i.e. 1000 * queries lines\n",
    "with open(f\"{data_dir}/BEIR/results_{dataset}_bm25_100.json\", 'w') as fp:\n",
    "    json.dump(bm25_results, fp)\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels_, bm25_results, retriever.k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14515345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG@1': 0.44,\n",
       " 'NDCG@3': 0.442,\n",
       " 'NDCG@5': 0.434,\n",
       " 'NDCG@10': 0.42897,\n",
       " 'NDCG@100': 0.50329,\n",
       " 'NDCG@1000': 0.53361}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c36dca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorspace.utils import json_load\n",
    "bm25_results = json_load(f\"{data_dir}/BEIR/results_{dataset}_bm25_100.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb0dbfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "class Rerank:\n",
    "    \n",
    "    def __init__(self, model, batch_size: int = 64, **kwargs):\n",
    "        self.cross_encoder = model\n",
    "        self.batch_size = batch_size\n",
    "        self.rerank_results = {}\n",
    "        \n",
    "    def rerank(self, \n",
    "               corpus: Dict[str, Dict[str, str]], \n",
    "               queries: Dict[str, str],\n",
    "               results: Dict[str, Dict[str, float]],\n",
    "               top_k: int) -> Dict[str, Dict[str, float]]:\n",
    "        \n",
    "        sentence_pairs, pair_ids = [], []\n",
    "        \n",
    "        for query_id in results:\n",
    "            if len(results[query_id]) > top_k:\n",
    "                for (doc_id, _) in sorted(results[query_id].items(), key=lambda item: item[1], reverse=True)[:top_k]:\n",
    "                    pair_ids.append([query_id, doc_id])\n",
    "                    corpus_text = (corpus[doc_id].get(\"title\", \"\") + \" \" + corpus[doc_id].get(\"text\", \"\")).strip()\n",
    "                    sentence_pairs.append([queries[query_id], corpus_text])\n",
    "            \n",
    "            else:\n",
    "                for doc_id in results[query_id]:\n",
    "                    pair_ids.append([query_id, doc_id])\n",
    "                    corpus_text = (corpus[doc_id].get(\"title\", \"\") + \" \" + corpus[doc_id].get(\"text\", \"\")).strip()\n",
    "                    sentence_pairs.append([queries[query_id], corpus_text])\n",
    "\n",
    "        #### Starting to Rerank using cross-attention\n",
    "        print(\"Starting To Rerank Top-{}....\".format(top_k))\n",
    "        rerank_scores = [float(score) for score in self.cross_encoder.predict(sentence_pairs, batch_size=self.batch_size)]\n",
    "\n",
    "        #### Reranking results\n",
    "        self.rerank_results = {query_id: {} for query_id in results}\n",
    "        for pair, score in zip(pair_ids, rerank_scores):\n",
    "            query_id, doc_id = pair[0], pair[1]\n",
    "            self.rerank_results[query_id][doc_id] = score\n",
    "\n",
    "        return self.rerank_results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279bacfb",
   "metadata": {},
   "source": [
    "## MiniLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a15d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c911b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir.reranking.models import CrossEncoder\n",
    "from beir.reranking import Rerank\n",
    "\n",
    "cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "reranker = Rerank(cross_encoder_model, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46840430",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder_model.model._target_device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127ed8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorspace.utils import json_load\n",
    "bm25_results = json_load(f\"{data_dir}/BEIR/results_bioasq_bm25_100.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de672ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373043e1b4264869a8c2d32e5a6ef7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rerank top-100 results retrieved by BM25\n",
    "rerank_results = reranker.rerank(corpus, queries_, bm25_results, top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ab328d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}/BEIR/results_bioasq_bm25_minilm_100.json', 'w') as fp:\n",
    "    json.dump(rerank_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "426587bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_results = json_load(f'{data_dir}/BEIR/results_bioasq_bm25_minilm_100.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d012afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(qrels_, rerank_results, [1, 3, 5, 10, 100, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74d5355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG@1': 0.55,\n",
       " 'NDCG@3': 0.48511,\n",
       " 'NDCG@5': 0.49446,\n",
       " 'NDCG@10': 0.5055,\n",
       " 'NDCG@100': 0.55799,\n",
       " 'NDCG@1000': 0.55799}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b9af625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Recall@1': 0.27609,\n",
       " 'Recall@3': 0.35597,\n",
       " 'Recall@5': 0.43591,\n",
       " 'Recall@10': 0.52172,\n",
       " 'Recall@100': 0.70038}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c298683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(qrels_, bm25_results, [1, 3, 5, 10, 100, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5969c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Recall@1': 0.21,\n",
       " 'Recall@3': 0.32956,\n",
       " 'Recall@5': 0.3762,\n",
       " 'Recall@10': 0.43371,\n",
       " 'Recall@100': 0.70038,\n",
       " 'Recall@1000': 0.85916}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
